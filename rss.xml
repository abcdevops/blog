<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.1.6">Jekyll</generator><link href="https://abcdevops.com/rss.xml" rel="self" type="application/atom+xml" /><link href="https://abcdevops.com/" rel="alternate" type="text/html" /><updated>2019-07-01T22:57:03-04:00</updated><id>https://abcdevops.com/</id><title>ABCDevOps: re:devining DevOps</title><subtitle>ABCDevOps: Let&#39;s discuss what devops is.</subtitle><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><entry><title>WOW! sending data to the could is thaaat easy :)</title><link href="https://abcdevops.com/blog/2019/06/25/what-is-cloud.html" rel="alternate" type="text/html" title="WOW! sending data to the could is thaaat easy :)" /><published>2019-06-25T00:00:00-04:00</published><updated>2019-06-25T00:00:00-04:00</updated><id>https://abcdevops.com/blog/2019/06/25/what-is-cloud</id><content type="html" xml:base="https://abcdevops.com/blog/2019/06/25/what-is-cloud.html">&lt;p&gt;How it would be if sending data to the cloud is that easy? #AWS, #Azure, #Cloud, #Google, #GCP.
&lt;!--more--&gt;
&lt;img src=&quot;/images/posts/send-data-to-cloud-black.jpg&quot; alt=&quot;before devops vs after devops&quot; /&gt;&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="Azure" /><category term="AWS" /><category term="GCP" /><category term="DevToon" /><summary>How it would be if sending data to the cloud is that easy? #AWS, #Azure, #Cloud, #Google, #GCP.</summary></entry><entry><title>Applcation development before DevOps vs after DevOps.</title><link href="https://abcdevops.com/blog/2019/06/24/before-devops.html" rel="alternate" type="text/html" title="Applcation development before DevOps vs after DevOps." /><published>2019-06-24T00:00:00-04:00</published><updated>2019-06-24T00:00:00-04:00</updated><id>https://abcdevops.com/blog/2019/06/24/before-devops</id><content type="html" xml:base="https://abcdevops.com/blog/2019/06/24/before-devops.html">&lt;p&gt;&lt;strong&gt;Application development before DevOps vs after DevOps.&lt;/strong&gt;
&lt;!--more--&gt;
&lt;img src=&quot;/images/posts/before-devops.png&quot; alt=&quot;before devops vs after devops&quot; /&gt;&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="Azure" /><category term="AWS" /><category term="GCP" /><category term="DevToon" /><summary>Application development before DevOps vs after DevOps.</summary></entry><entry><title>What, Servers are on strike. We need some superman?</title><link href="https://abcdevops.com/blog/2019/06/05/servers-on-strike.html" rel="alternate" type="text/html" title="What, Servers are on strike. We need some superman?" /><published>2019-06-05T00:00:00-04:00</published><updated>2019-06-05T00:00:00-04:00</updated><id>https://abcdevops.com/blog/2019/06/05/servers-on-strike</id><content type="html" xml:base="https://abcdevops.com/blog/2019/06/05/servers-on-strike.html">&lt;p&gt;&lt;strong&gt;Allow #ABCDevOps to be the #UnionLeader and keep your servers in your service.&lt;/strong&gt;
&lt;!--more--&gt;
&lt;img src=&quot;/images/posts/servers-are-off.jpg&quot; alt=&quot;Where are you going? Our clients are still in queue.&quot; /&gt;&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="Azure" /><category term="AWS" /><category term="GCP" /><category term="DevToon" /><summary>Allow #ABCDevOps to be the #UnionLeader and keep your servers in your service.</summary></entry><entry><title>Amazon EC2 - Elastic Cloud Computing</title><link href="https://abcdevops.com/blog/2016/03/02/amazon-EC2.html" rel="alternate" type="text/html" title="Amazon EC2 - Elastic Cloud Computing" /><published>2016-03-02T00:00:00-05:00</published><updated>2016-03-02T00:00:00-05:00</updated><id>https://abcdevops.com/blog/2016/03/02/amazon-EC2</id><content type="html" xml:base="https://abcdevops.com/blog/2016/03/02/amazon-EC2.html">&lt;p&gt;Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides re-sizable compute capacity in the cloud. &lt;!--more--&gt;
Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change.&lt;/p&gt;

&lt;p&gt;We are working from last 10 years in IT I remember time where if we needed a new Active Directory Server or a new SQL Server we have to go to HP or go to DELL order new servers we then had to get deliver to our data centers we had to get racked we had to do the networking setup them the internet accessible etc and you know your provisioning time should be anywhere from 5 to 10 business days. Then i started public cloud and was really exciting to see the capabilities of cloud in step having of 5 to 10 days lead time you would reduce to literally just couple of minutes you can have that server up and running so that’s really how cloud computing change the IT industry in the last 5 to 10 years so Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use. Amazon EC2 provides developers the tools to build failure resilient applications and isolate themselves from common failure scenarios. So we just look at the first section the advantage of the cloud computing is utility based model you can pay only by the hour. If you want to spin up the development environment and just test on it and then terminate you only pay for 1 or 2 hours the environment is live the old model way you would buy the server hardware you would be stuck with it.&lt;/p&gt;

&lt;h2 id=&quot;elastic-compute-cloud-pricing-options&quot;&gt;Elastic Compute Cloud Pricing Options&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;free-tier-&quot;&gt;Free Tier –&lt;/h5&gt;
    &lt;p&gt;you get 735 hours free on certain micro instances.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;on-demand-&quot;&gt;On Demand –&lt;/h5&gt;
    &lt;p&gt;Which allow you to pay a fixed rate by the hour with no commitment.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;reserved-&quot;&gt;Reserved –&lt;/h5&gt;
    &lt;p&gt;Which provide you with a capacity reservation, and offer a significant discount on the hourly charge for an instance. Then you have 1 Year or 3 Year Terms so reserved just saying i need 10 servers of this size and i am willing to pay either up-front contractual willing to commit for 1 to 3 years and if you do use reserved instances then you get massive discounts compared with on demand.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;spot-&quot;&gt;Spot –&lt;/h5&gt;
    &lt;p&gt;This is enable you to bid whatever price you want to pay for instance capacity, providing for even greater savings if your applications have flexible start and end times.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;elastic-compute-cloud-on-demand-vs-reserved-vs-spot&quot;&gt;Elastic Compute Cloud On Demand vs Reserved vs Spot&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;on-demand-instances&quot;&gt;On Demand Instances&lt;/h5&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Users that want the low cost and flexibility of Amazon EC2 without any up-front payment or long-term commitment.&lt;/span&gt;
&lt;span&gt;Applications with short term, spike, or unpredictable workloads that cannot be interrupted.&lt;/span&gt;
&lt;span&gt;Applications being developed or tested on Amazon EC2 for the first time.&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;reserved-instances&quot;&gt;Reserved Instances&lt;/h5&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Applications with steady state or predictable usage so reserved might be your 3 or 4 web servers that you always want to turned on and then your on demand instances might be is the part of an auto scaling event.&lt;/span&gt;
&lt;span&gt;Applications that require reserved capacity.&lt;/span&gt;
&lt;span&gt;Users able to make upfront payment to reduce their total computing costs even further.&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;spot-instances&quot;&gt;Spot Instances&lt;/h5&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;  Applications that have flexible start and end times.&lt;/span&gt;
&lt;span&gt;Applications that are only feasible at very low compute prices.&lt;/span&gt;
&lt;span&gt;Users with urgent computing needs for large amounts  of additional capacity.&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;elastic-compute-cloud-on-demand-instances&quot;&gt;Elastic Compute Cloud On Demand Instances&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;General Purpose Instances&lt;/li&gt;
  &lt;li&gt;Compute Optimized Instances
 &lt;span&gt;Compute Intensive Applications&lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;Memory Optimized Instances
  &lt;span&gt;Database &amp;amp; Memory Caching Applications&lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;GPU Instances Instances
  &lt;span&gt;High Performance Parallel Computing (eg Hadoop)&lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;Storage Optimized Instances
  &lt;span&gt;Data warehousing and Parallel Computing&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;local-instance-storage-vs-elastic-block-storage&quot;&gt;Local Instance Storage vs Elastic Block Storage&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Local Instance Storage&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Data stored on a local instance store will persist only as long as that instance is alive. So you terminate that Instances you loose all the data on that virtual hardware.&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Elastic Block Storage Backed Storage&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Data that is stored on an Amazon Elastic Block Storage volume will persist independently of the life of the instance.&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;storage-backed-by-elastic-block-storage&quot;&gt;Storage backed by Elastic Block Storage&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Provisioned IOPS Solid State Drive&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Designed for I/O intensive applications such as large relational or No-SQL databases.&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;General purpose Solid State Drive&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Designed for 99.999% availability.&lt;/span&gt;
&lt;span&gt;Ratio of 3 IOPS per GB, offer single digit millisecond latency, and also have the ability to burst up to 3000 IOPS for short periods.&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;magnetic&quot;&gt;Magnetic&lt;/h5&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Lowest cost per gigabyte of all Elastic Block Storage volume types. Magnetic volumes are ideal for workloads where data is accessed infrequently, and applications where the lowest storage cost is important.&lt;/span&gt;&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="ec2" /><category term="amazon" /><category term="aws" /><category term="service" /><category term="pricing" /><summary>Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides re-sizable compute capacity in the cloud.</summary></entry><entry><title>Amazon Lambda - Serverless technology</title><link href="https://abcdevops.com/blog/2016/02/29/amazon-lambda.html" rel="alternate" type="text/html" title="Amazon Lambda - Serverless technology" /><published>2016-02-29T00:00:00-05:00</published><updated>2016-02-29T00:00:00-05:00</updated><id>https://abcdevops.com/blog/2016/02/29/amazon-lambda</id><content type="html" xml:base="https://abcdevops.com/blog/2016/02/29/amazon-lambda.html">&lt;h2 id=&quot;what-is-lambda&quot;&gt;What is Lambda?&lt;/h2&gt;

&lt;p&gt;AWS Lambda is a compute service that runs your code in response to events and automatically manages the underlying compute resources. So you don’t have to worry about server infrastructure all you have to worry about is code and you can design your code respond automatically to events.
&lt;!--more--&gt;
AWS Lambda can automatically run code in response to modifications to objects in Amazon S3 buckets, messages arriving in Amazon Kinesis streams, or table updates in Amazon DynamoDb.&lt;/p&gt;

&lt;p&gt;Lambda runs your code on high-availability compute infrastructure and performs all the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code and security patch deployment, and code monitoring and logging.&lt;/p&gt;

&lt;p&gt;All you need to do is supply the code.&lt;/p&gt;

&lt;h2 id=&quot;what-events-trigger-lambda&quot;&gt;What Events Trigger Lambda?&lt;/h2&gt;

&lt;p&gt;You can use AWS Lambda to respond to table updates in Amazon DynamoDB, modifications to objects in Amazon S3 buckets, messages arriving in an Amazon Kinesis stream, AWS API calls logs created by AWS Cloud Trail, and custom events from mobile applications, web applications, or other web services.&lt;/p&gt;

&lt;h2 id=&quot;lambda-pricing&quot;&gt;Lambda Pricing&lt;/h2&gt;

&lt;p&gt;So pricing is broken down into two bits Requests based and Duration based. So if we start with requests you get first 1 million requests are free to the Lambda service and then you are paying $0.20 per 1 million requests thereafter.&lt;/p&gt;

&lt;p&gt;Duration is calculated from the time your code begins executing until it returns or otherwise terminates, and it’s rounded up to the nearest 100ms. The price depends on the amount of memory you allocate to your function. You are charged $0.00001667 for every GB-second used.&lt;/p&gt;

&lt;p&gt;In terms of your free tier&lt;/p&gt;

&lt;p&gt;1M free requests per month and 400,000 GB-seconds of compute time per month. The memory size you choose for your Lambda functions determines how long they can run in the free tier. The Lambda free tier does not automatically expire at the end of your 12 month AWS Free Tier term, but is available in both existing and new AWS customers indefinitely.&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="serverless" /><category term="lambda" /><category term="amazon" /><category term="aws" /><category term="service" /><category term="pricing" /><summary>What is Lambda?

AWS Lambda is a compute service that runs your code in response to events and automatically manages the underlying compute resources. So you don’t have to worry about server infrastructure all you have to worry about is code and you can design your code respond automatically to events.</summary></entry><entry><title>Amazon S3 - Simple storage service</title><link href="https://abcdevops.com/blog/2016/02/27/amazon-S3.html" rel="alternate" type="text/html" title="Amazon S3 - Simple storage service" /><published>2016-02-27T00:00:00-05:00</published><updated>2016-02-27T00:00:00-05:00</updated><id>https://abcdevops.com/blog/2016/02/27/amazon-S3</id><content type="html" xml:base="https://abcdevops.com/blog/2016/02/27/amazon-S3.html">&lt;h2 id=&quot;simple-storage-service-s3&quot;&gt;Simple Storage Service (S3):&lt;/h2&gt;

&lt;p&gt;S3 provides developers and IT teams with secure, durable, highly-scalable object storage. Amazon S3 is easy to use, with a simple web services interfaces to store and retrieve any amount of data from anywhere on the web.
&lt;!--more--&gt;
S3 Essentials
—&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;S3 is Object based i.e. allows you to upload files and stored file on the platform.&lt;/li&gt;
  &lt;li&gt;Files can be from 1 Byte to 5Tb in size.&lt;/li&gt;
  &lt;li&gt;There is unlimited storage.&lt;/li&gt;
  &lt;li&gt;Files are stored in Buckets. (Buckets like directory any windows and linux file system).&lt;/li&gt;
  &lt;li&gt;Buckets have a unique namespace for each given region (eg if i want to create a bucket izapcloudguru in the eu-west-1 region that namespace with then be reserved so somebody else with using another amazon account could not go in and create a izapcloudguru bucket. https://s3-eu-west-1.amazonaws.com/bucketname/)&lt;/li&gt;
  &lt;li&gt;Amazon guarantees 99.99% availability for the S3 platform. S3 buckets essentially spread across availability zone. So if availability zone goes down you don’t have to worry your S3 bucket is stored in the other availability zone and amazon do this automatically on a region bases you don’t have to worry about configuring this.&lt;/li&gt;
  &lt;li&gt;Amazon also guarantees 99.999999999% durability for S3 information. Durability is simply if you think of storing of file on a disk set i.e Raid 1 and you lose one of the disk because in Raid 1 configuration which mirror all your information is stored across two disks so you can loss of 1 disk now the way amazon structure S3 is that if you stored 10000 files the guarantee those 10000 files stay there with the 99.999999999% durability.&lt;/li&gt;
  &lt;li&gt;S3 can have metadata (key value pairs) on each storage (eg file).&lt;/li&gt;
  &lt;li&gt;S3 allows you to do Lifecycle Management.&lt;/li&gt;
  &lt;li&gt;Versioning&lt;/li&gt;
  &lt;li&gt;Encryption (S3 also allows you to do encrypt your buckets. You can store your files encrypted at rest.)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;s3-storage-types&quot;&gt;S3 Storage Types&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Standard S3 storage which gives you 99.99% availability, and the 99.999999999% durability&lt;/li&gt;
  &lt;li&gt;Reduced Redundancy storage – Still has 99.99% availability and your buckets replicated across different availability zones automatically but they use different disk sets the only give you 99.99% durability over a given year. So it’s little bit cheaper to use reduced redundancy storage but you only stored files on that not important if you lose them.&lt;/li&gt;
  &lt;li&gt;Only use Reduced Redundancy Storage for replaceable data. For example if you have 10,000 files, you could expect to lose 100 files over 1 year as opposed to 0.00001 file with standard S3 durability.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;s3-versioning&quot;&gt;S3 Versioning&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Stores all versions of an object (including all writes and even if you delete an object)&lt;/li&gt;
  &lt;li&gt;Great backup tool.&lt;/li&gt;
  &lt;li&gt;Once enabled, Versioning cannot be disabled, only suspended that’s quite important to know.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;s3-lifecycle-management&quot;&gt;S3 Lifecycle Management&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Lifecycle Management can be used in conjunction with versioning.&lt;/li&gt;
  &lt;li&gt;Lifecycle Management can be applied to current versions and previous versions.&lt;/li&gt;
  &lt;li&gt;Following actions are allowed in conjunction with or without versioning;&lt;/li&gt;
  &lt;li&gt;Archive Only&lt;/li&gt;
  &lt;li&gt;Permanently Delete Only&lt;/li&gt;
  &lt;li&gt;Archive and then permanently delete.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;s3-encryption&quot;&gt;S3 Encryption&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;You can upload/download your data to S3 via SSL Encrypted Endpoints and S3 can automatically encrypt your data at rest. S3 gives you the choice of managing your keys through AWS key Management Service (AWS Key Management Service), having Amazon S3 manage them for you, or providing your own keys.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;s3-security&quot;&gt;S3 Security&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;All buckets are private by default.&lt;/li&gt;
  &lt;li&gt;Allows Access Control Lists (an individual user, can only have access to 1 bucket and only have read only access).&lt;/li&gt;
  &lt;li&gt;Integrates with IAM (using roles for example allows EC2 users to have access S3 buckets by roles).&lt;/li&gt;
  &lt;li&gt;All endpoints are encrypted by SSL.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;s3-functionality&quot;&gt;S3 Functionality&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Static Websites can be hosted on S3. No need for web servers, you can just upload a static .html to an S3 bucket and take advantage of AWS S3’s durability and High Availability.&lt;/li&gt;
  &lt;li&gt;S3 also Integrates with Cloud Front which is amazon content delivering network.&lt;/li&gt;
  &lt;li&gt;Multipart uploads, allows you to upload parts of a file concurrently.&lt;/li&gt;
  &lt;li&gt;Suggested for files a 100Mb over. It is required for any file over 5Gbs.&lt;/li&gt;
  &lt;li&gt;Allows us to resume a stopped file upload.&lt;/li&gt;
  &lt;li&gt;S3 is spread across multiple availability zones and i guarantee you have Eventual Consistency you just have to remember the sometimes you might upload a file to an S3 bucket and then you go to try and access that file programmatically because you  trying to do that so fast it might not replicated across other availability zones. So just important to remember that all AZ’s will eventually be consistent. Put/Write/Delete requests will eventually be consistent across AZ’s.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;s3-use-cases&quot;&gt;S3 Use Cases&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;File Shares for networks&lt;/li&gt;
  &lt;li&gt;Backup/Archiving&lt;/li&gt;
  &lt;li&gt;Origin for CloudFront CDN’s&lt;/li&gt;
  &lt;li&gt;Hosting Static Files&lt;/li&gt;
  &lt;li&gt;Hosting Static Websites&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="s3" /><category term="storage" /><category term="amazon" /><category term="aws" /><category term="service" /><category term="pricing" /><summary>Simple Storage Service (S3):

S3 provides developers and IT teams with secure, durable, highly-scalable object storage. Amazon S3 is easy to use, with a simple web services interfaces to store and retrieve any amount of data from anywhere on the web.</summary></entry><entry><title>Amazon Cloud Front - serve static assets from the closest place.</title><link href="https://abcdevops.com/blog/2016/02/24/amazon-cloud-front.html" rel="alternate" type="text/html" title="Amazon Cloud Front - serve static assets from the closest place." /><published>2016-02-24T00:00:00-05:00</published><updated>2016-02-24T00:00:00-05:00</updated><id>https://abcdevops.com/blog/2016/02/24/amazon-cloud-front</id><content type="html" xml:base="https://abcdevops.com/blog/2016/02/24/amazon-cloud-front.html">&lt;h2 id=&quot;cdn-&quot;&gt;CDN:-&lt;/h2&gt;

&lt;p&gt;A Content Delivery Network (CDN) is a system of distributed servers (network) that deliver web pages and other web content to a user based on the geographic locations of the user, the origin of the webpage and a content delivery server. &lt;!--more--&gt;
Now, let’s look at a practical example if i am in Australia let say i am in Perth for example and i want access the server in New York that server has image files on it in order get those image files the actual image files have to be served across the Atlantic then across the Indian ocean in order to reach Perth and every 200Kms equals to approximately 1 millisecond length of time latency so it’s take me a little bit of time for those files to physically arrived for New York to Perth a even operating a speed of light it’s gonna be a longer time than a files viewing those files directly from a server in Perth so our Content Distribution Network does its every time a user in Perth tries to access those files in New York CDN cache those files add a server in Perth for the length of time. Now a new user goes to access the same files they can just get it from Perth server they don’t have to go halfway around the world to pull down the same files. Those files will be cached depending on the settings but you set was called it time to live (TTL) and that’s measured in seconds you can set on your CDN you can set TTL on your files to say how long you are going to cache them. So that a really high overview what CDN is and CloudFront is Amazon CDN.&lt;/p&gt;

&lt;p&gt;Amazon CloudFront can be used to deliver your entire website, including dynamic, static, streaming, and interactive content using a global network of edge locations. Requests for your content are automatically routed to the nearest edge location, so the content is delivered with the best possible performance.&lt;/p&gt;

&lt;p&gt;Amazon CloudFront is optimized to work with other Amazon Web Services, like Amazon Simple Storage Service (Amazon S3), Amazon Elastic Compute Cloud (Amazon EC2), Amazon Elastic Load Balancing, and Amazon Route 53. Amazon CloudFront also works seamlessly with any non-AWS origin server, which stores the original, definitive versions of your files.&lt;/p&gt;

&lt;h2 id=&quot;cloudfront-terminology&quot;&gt;CloudFront Terminology&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;origin-&quot;&gt;Origin –&lt;/h5&gt;
    &lt;p&gt;This is the origin of all the files that the CDN will distributed. This can be either an S3 Bucket, an EC2 Instance, an Elastic Load Balancer or Route53.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;distribution-&quot;&gt;Distribution –&lt;/h5&gt;
    &lt;p&gt;This is the name given the CDN which consists of a collection of Edge Locations. You can have 1 distribution with multiple origins and good example of this would be where buy to trying to serve a dynamic website and may be your image files or stored flat static files that be stored in an s3 bucket. You also running a PHP application it does not refresh to often and you want to cache the output of those PHP files you can create a separate origin server which should be an EC2 instance for example and then any PHP files would come from your EC2 instance image file comes from your S3 buckets. You can also have multiple S3 buckets with different files types perhaps you have an S3 buckets for your pdf files we have a separate S3 buckets for application users will download. So you can have 1 distribution will multiple origins.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;cloudfront-distribution-types&quot;&gt;CloudFront Distribution Types&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;web-distribution-&quot;&gt;Web Distribution –&lt;/h5&gt;
    &lt;p&gt;Typically used for websites&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Speed up distribution of static and dynamic content, for example, .html, .css, .php, and graphics files.&lt;/span&gt;
  &lt;span&gt;Distribute media files using HTTP or HTTPS.&lt;/span&gt;
  &lt;span&gt;Add, update, or delete objects, and submit data from web forms.&lt;/span&gt;
  &lt;span&gt;Use live streaming to stream an event in real time.&lt;/span&gt;
  &lt;span&gt;You store your files in an origin — either an Amazon S3 bucket or a web server. After you create the distribution, you can add more origins to the distribution.&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;rtmp-&quot;&gt;RTMP –&lt;/h5&gt;
    &lt;p&gt;RTMP distribution to speed up distribution of your streaming media files using Adobe Flash Media Servers RTMP protocol. An RTMP distribution allows an end user to begin playing a media file before the file has finished downloading from a CloudFront edge location. Note the following:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;To create an RTMP distribution, you must store the media files in an Amazon S3 bucket.&lt;/span&gt;
  &lt;span&gt;To use CloudFront live streaming, create a web distribution.&lt;/span&gt;&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="CloudFront" /><category term="CDN" /><category term="amazon" /><category term="aws" /><category term="service" /><category term="pricing" /><summary>CDN:-

A Content Delivery Network (CDN) is a system of distributed servers (network) that deliver web pages and other web content to a user based on the geographic locations of the user, the origin of the webpage and a content delivery server.</summary></entry><entry><title>Amazon Storage Gateway - Better storage solution.</title><link href="https://abcdevops.com/blog/2016/02/22/amazon-storage-gateway.html" rel="alternate" type="text/html" title="Amazon Storage Gateway - Better storage solution." /><published>2016-02-22T00:00:00-05:00</published><updated>2016-02-22T00:00:00-05:00</updated><id>https://abcdevops.com/blog/2016/02/22/amazon-storage-gateway</id><content type="html" xml:base="https://abcdevops.com/blog/2016/02/22/amazon-storage-gateway.html">&lt;h2 id=&quot;storage-gateway&quot;&gt;Storage Gateway&lt;/h2&gt;

&lt;p&gt;AWS Storage Gateway is a service that connects an on-premises software appliance with cloud-based storage to provide seamless and secure integration between an organization’s on-premises IT environment and AWS’s storage infrastructure.&lt;!--more--&gt;
 The service enables you to securely store data to the AWS cloud for scalable and cost-effective storage.&lt;/p&gt;

&lt;p&gt;AWS Storage Gateway software appliance is available for download as a virtual machine (VM) image that you install on a host in your data center. Once you’ve installed your gateway and associated it with your AWS account through our activation process, you can use the AWS Management Console to create either gateway-cached or gateway-stored volumes that can be mounted as iSCSI devices by your on-premises applications.&lt;/p&gt;

&lt;h2 id=&quot;storage-gateway-in-two-different-models-gateway-cached-and-gateway-stored&quot;&gt;Storage Gateway in two different models Gateway-cached and Gateway-stored&lt;/h2&gt;

&lt;h2 id=&quot;gateway-cached--&quot;&gt;Gateway-cached :-&lt;/h2&gt;
&lt;p&gt;Gateway-cached volumes allow you to utilize Amazon S3 for your primary data, while retaining some portion of it locally in a cache for frequently accessed data. These volumes minimize the need to scale your on-premises storage infrastructure, while still providing your applications with low-latency access to their  frequently accessed data. You can create storage volumes up to 32 TBs in size and mount them as iSCSI devices from your on-premises application servers. Data written to these volumes is stored in Amazon S3, with only a cache of recently written and recently read data stored locally on your on-premises storage hardware.&lt;/p&gt;

&lt;h2 id=&quot;gateway-stored--&quot;&gt;Gateway-stored :-&lt;/h2&gt;

&lt;p&gt;Gateway-stored volumes store your primary data locally, while asynchronously backing up that data to AWS. These volumes provide your on-premises applications with low-latency access to their entire data sets, while providing durable, off-site backups. You can create storage volumes up to 1TB in size and mount them as iSCSI devices from your on-premises applications servers. Data written to your gateway-stored volumes is stored on your on-premises storage hardware, and asynchronously backed up to Amazon S3 in the form of Amazon EBS snapshots.&lt;/p&gt;

&lt;h2 id=&quot;storage-gateway-pricing&quot;&gt;Storage Gateway Pricing&lt;/h2&gt;

&lt;p&gt;With AWS Storage Gateway, you pay only for what you use. AWS Storage Gateway has four pricing components: gateway usage (per GB per month) so the number of gateway using per month, snapshot storage usage (per GB per month), volume storage usage (per GB per month), and data transfer out (per GB per month).&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="sqs" /><category term="amazon" /><category term="aws" /><category term="service" /><category term="pricing" /><summary>Storage Gateway

AWS Storage Gateway is a service that connects an on-premises software appliance with cloud-based storage to provide seamless and secure integration between an organization’s on-premises IT environment and AWS’s storage infrastructure.</summary></entry><entry><title>Amazon RDS - Relational database service</title><link href="https://abcdevops.com/blog/2016/02/20/amazon-RDS.html" rel="alternate" type="text/html" title="Amazon RDS - Relational database service" /><published>2016-02-20T00:00:00-05:00</published><updated>2016-02-20T00:00:00-05:00</updated><id>https://abcdevops.com/blog/2016/02/20/amazon-RDS</id><content type="html" xml:base="https://abcdevops.com/blog/2016/02/20/amazon-RDS.html">&lt;h2 id=&quot;databases-introduction&quot;&gt;Databases Introduction&lt;/h2&gt;

&lt;p&gt;So we just with brief introduction on the different types of databases so we got Relational databases.&lt;!--more--&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;relational-databases-oltp--&quot;&gt;Relational Databases (OLTP) :-&lt;/h5&gt;
    &lt;p&gt;Online Transaction Processing these are the databases that used to using day in day.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;RDS :-  Amazon have a service code RDS which stands for Relational Database Services. In this consist of 5 different relational databases including (MYSQL, SQL Server, POSTgresql, Oracle, and Aurora)&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;non-relational-databases-nosql--&quot;&gt;Non-Relational Databases (NOSQL) :-&lt;/h5&gt;
    &lt;p&gt;These aggressively new to the industry having sort of come out around 2004 also and Amazon service for this is :&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Dynamodb :-  Most famous Non-relational database would be something like Mongodb are you could look at cloud end Couchdb. Dynamodb is slightly different to these databases do not compare with Mongodb.&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;h5 id=&quot;data-warehousing-databases-olap--&quot;&gt;Data Warehousing Databases (OLAP) :-&lt;/h5&gt;
    &lt;p&gt;Online Analytical Processing and these over the use to be relational structure both from a logical perspective and it infrastructure perspective has not changed and these really there are types of databases these known as Data Warehousing Databases. Amazon offers for this product code:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;RedShift&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;compare-the-fundamentals&quot;&gt;Compare The Fundamentals&lt;/h2&gt;

&lt;p&gt;So Let’s start with the Relational Databases or Amazon RDS so it’s for what most of us are used to. Been around since the 1970’s.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Database&lt;/li&gt;
  &lt;li&gt;Tables :- Inside your database you got number of tables.&lt;/li&gt;
  &lt;li&gt;Row :- Inside your tables you got Row otherwise knows as Record.&lt;/li&gt;
  &lt;li&gt;Fields :- That Row or Record consists number of fields which known as colum&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;RDS includes technologies such as :-&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;Oracle&lt;/li&gt;
  &lt;li&gt;MySQL Server&lt;/li&gt;
  &lt;li&gt;Postgres&lt;/li&gt;
  &lt;li&gt;Aurora&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;nosql-database-structure--&quot;&gt;NoSql Database Structure :-&lt;/h2&gt;

&lt;p&gt;NoSql quite a little bit different to relational databases so there is different types of NoSql i am gonna talk about document oriented databases in this  That’s by Dynamodb is you can also get tabular you get key value pairs you get different types of NoSql databases with the ones we are going to look at document oriented.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Collection :- So Inside your database you have got a collection.&lt;/li&gt;
  &lt;li&gt;Document :- Inside your collection and you got a number of documents.&lt;/li&gt;
  &lt;li&gt;Key Value Pairs :- Those documents consist of key value pairs.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;data-warehousing--&quot;&gt;Data Warehousing :-&lt;/h2&gt;

&lt;p&gt;This is often used by number of different software products business intelligence. Tools like Cognos, Jaspersoft, SQL Server Reporting Services, Oracle Hyperion, SAP NetWeaver.&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="RDS" /><category term="oracle" /><category term="mysql" /><category term="PostgreSQL" /><category term="amazon" /><category term="aws" /><category term="service" /><category term="pricing" /><summary>Databases Introduction

So we just with brief introduction on the different types of databases so we got Relational databases.</summary></entry><entry><title>Amazon DynamoDB - NoSQL database for faster response time</title><link href="https://abcdevops.com/blog/2016/02/17/amazon-dynamoDB.html" rel="alternate" type="text/html" title="Amazon DynamoDB - NoSQL database for faster response time" /><published>2016-02-17T00:00:00-05:00</published><updated>2016-02-17T00:00:00-05:00</updated><id>https://abcdevops.com/blog/2016/02/17/amazon-dynamoDB</id><content type="html" xml:base="https://abcdevops.com/blog/2016/02/17/amazon-dynamoDB.html">&lt;h2 id=&quot;dynamodb&quot;&gt;DynamoDB&lt;/h2&gt;

&lt;p&gt;Amazon DynamoDB is a fast and flexible No-SQL database service for all applications that need consistent, single-digit millisecond latency at any scale. &lt;!--more--&gt;
It is a fully managed database and supports both document and key-value data models. It’s flexible data model and reliable performance make it a great fit for mobile, web, gaming, ad-tech, IoT, and many other applications.&lt;/p&gt;

&lt;h2 id=&quot;dynamodb-configuration&quot;&gt;DynamoDB Configuration&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;It’s always going to be stored on SSD storage. So there is no magnetic storage you going to get very good and very high IOPS from it.&lt;/li&gt;
  &lt;li&gt;It is Spread Across 3 different geographically distinct data centers. So if you write a database you write a record to a particular a AZ that is going to be replicated across to your other two AZ and in terms of that replication you can choose between two options;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Eventual Consistent Reads&lt;/span&gt;
&lt;span&gt;Strongly Consistent Reads&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;difference-between-eventual-consistent-reads-and-strongly-consistent-reads&quot;&gt;Difference Between Eventual Consistent Reads and Strongly Consistent Reads&lt;/h2&gt;

&lt;h2 id=&quot;eventual-consistent-reads--&quot;&gt;Eventual Consistent Reads :-&lt;/h2&gt;

&lt;p&gt;Consistency across all copies of data is usually reached within a second. Repeating a read after a short time should return the updated data. (Best Read Performance). So this means that when you run a read query against your database you might be querying at two unavailability zone that has not yet had that data that is been from the initial write which should be another AZ has not been replicated across. So let say you are writing your data to AZ-(A) and then when you going to read the database it might not be the in AZ-(B) depending on the length of the time between that write and that read that would be Eventual Consistent.&lt;/p&gt;

&lt;h2 id=&quot;strongly-consistent-reads--&quot;&gt;Strongly Consistent Reads :-&lt;/h2&gt;

&lt;p&gt;A strongly consistent read returns a result that reflects all writes that received a successful response prior to the read. So with Strongly Consistent Reads you would not get the same read performance you get with the Eventual Consistent Reads but you do more less guarantee reflect that after somebody has written record to AZ-(A) nobody would be able to read that record in AZ-(B) into has been replicated across. So just keep that in mind when you designing your application whether or not (We are talking about millisecond you know we are not talking within a seconds) so it’s really up to you and your application team is to which one the you would choose most people choose the default which is you know we can afford for my data to be out of date or not replicated within a second so that its Eventual Consistent Reads.&lt;/p&gt;

&lt;h2 id=&quot;pricing&quot;&gt;Pricing&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Provisioned Throughput Capacity&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span&gt;Write Throughput $0.0065 per hour for every 10 units.&lt;/span&gt;
&lt;span&gt;Read Throughput $0.0065 per hour for every 50 units.&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Storage costs of $0.25Gb per month.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;pricing-example&quot;&gt;Pricing Example&lt;/h2&gt;

&lt;p&gt;Let’s assume that your application needs to perform 1 million writes and 1 million reads per day, while storing 3GB of data.&lt;/p&gt;

&lt;p&gt;First, you need to calculate how many writes and reads per second you need. 1 million evenly spread writes per day is equivalent to 1,000,000 (writes) /24 (hours) /60 (minutes) /60 (seconds) = 11.6 writes per second.&lt;/p&gt;

&lt;p&gt;A DynamoDB Write Capacity Unit can handle 1 write per second, so you need 12 Writes Capacity Units. Similarly, to handle 1 million strongly consistent reads per day, you need 12 Read Capacity Units.&lt;/p&gt;

&lt;p&gt;Using on-demand pricing in the US East (N. Virginia) Region. You got 12 Write Capacity Units would cost $0.1872 per day and 12 Read Capacity Units would cost $0.0374 per day. So your total cost of provisioned throughput capacity is $0.1872 + $ 0.03474 = $0.2246 per day. Storage costs $0.25 per GB per month.&lt;/p&gt;

&lt;p&gt;Assuming a 30-day month, your 3GB would cost you 3 * $0.25/30 = $0.025 per day. Combining these numbers, the total cost of your DynamoDB table would be $0.2246 (for provisioned throughput capacity) + $0.025 (for storage) = $0.2496 per day or $7.50 per month.&lt;/p&gt;</content><author><name>Tarun Jangra</name><email>tarun.jangra@abcdevops.com</email></author><category term="sqs" /><category term="amazon" /><category term="aws" /><category term="service" /><category term="pricing" /><summary>DynamoDB

Amazon DynamoDB is a fast and flexible No-SQL database service for all applications that need consistent, single-digit millisecond latency at any scale.</summary></entry></feed>
